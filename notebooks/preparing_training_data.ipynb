{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>measure</th>\n",
       "      <th>composer</th>\n",
       "      <th>corpus</th>\n",
       "      <th>partition</th>\n",
       "      <th>notes</th>\n",
       "      <th>node_id</th>\n",
       "      <th>pitch</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>bach</td>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>horn__</td>\n",
       "      <td>['F4', 1.0]</td>\n",
       "      <td>0</td>\n",
       "      <td>F4</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bach</td>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>horn__</td>\n",
       "      <td>['G4', 0.5]</td>\n",
       "      <td>1</td>\n",
       "      <td>G4</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>bach</td>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>horn__</td>\n",
       "      <td>['C4', 0.5]</td>\n",
       "      <td>2</td>\n",
       "      <td>C4</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>bach</td>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>horn__</td>\n",
       "      <td>['F4', 0.5]</td>\n",
       "      <td>3</td>\n",
       "      <td>F4</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>bach</td>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>horn__</td>\n",
       "      <td>['F3', 0.5]</td>\n",
       "      <td>4</td>\n",
       "      <td>F3</td>\n",
       "      <td>0.5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   measure composer  corpus partition        notes  node_id pitch duration\n",
       "0        0     bach  bwv1.6    horn__  ['F4', 1.0]        0    F4   1.0000\n",
       "1        1     bach  bwv1.6    horn__  ['G4', 0.5]        1    G4   0.5000\n",
       "2        1     bach  bwv1.6    horn__  ['C4', 0.5]        2    C4   0.5000\n",
       "3        1     bach  bwv1.6    horn__  ['F4', 0.5]        3    F4   0.5000\n",
       "4        1     bach  bwv1.6    horn__  ['F3', 0.5]        4    F3   0.5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "input_path = Path(\"..\\\\data\\\\01_preprocessed\\\\bach.csv\")\n",
    "all_files = pd.read_csv(input_path, sep=\";\", dtype={\"duration\":str})\n",
    "all_files.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define duration vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0000    55776\n",
      "0.5000    39690\n",
      "2.0000     6925\n",
      "0.2500     5463\n",
      "3.0000     2341\n",
      "1.5000     1456\n",
      "4.0000     1107\n",
      "0.7500      150\n",
      "0.1250       86\n",
      "6.0000       21\n",
      "8.0000        4\n",
      "0.0000        3\n",
      "Name: duration, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['0.0000',\n",
       " '0.1250',\n",
       " '0.2500',\n",
       " '0.3750',\n",
       " '0.5000',\n",
       " '0.6250',\n",
       " '0.7500',\n",
       " '0.8750',\n",
       " '1.0000',\n",
       " '1.1250',\n",
       " '1.2500',\n",
       " '1.3750',\n",
       " '1.5000',\n",
       " '1.6250',\n",
       " '1.7500']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(all_files.duration.value_counts())\n",
    "duration_vocab = [f\"{x:.4f}\" for x in np.arange(.0, 8.1, .125)]\n",
    "duration_vocab[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pitch vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "D4      7905\n",
       "G4      6905\n",
       "A4      6823\n",
       "E4      6785\n",
       "A3      6066\n",
       "        ... \n",
       "C#2        1\n",
       "D#2        1\n",
       "G-5        1\n",
       "F##4       1\n",
       "F##3       1\n",
       "Name: pitch, Length: 85, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_files.pitch.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A1',\n",
       " 'A2',\n",
       " 'A3',\n",
       " 'A4',\n",
       " 'A5',\n",
       " 'A6',\n",
       " 'A#1',\n",
       " 'A#2',\n",
       " 'A#3',\n",
       " 'A#4',\n",
       " 'A#5',\n",
       " 'A#6',\n",
       " 'A##1',\n",
       " 'A##2',\n",
       " 'A##3']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "octaves = range(1, 7, 1)\n",
    "accents = [\"\", \"#\", \"##\", \"-\", \"--\"]\n",
    "pitches = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\"]\n",
    "\n",
    "pitch_vocab = []\n",
    "for pitch in pitches:\n",
    "    for accent in accents:\n",
    "        for octave in octaves:\n",
    "            pitch_vocab.append(f\"{pitch}{accent}{octave}\")\n",
    "\n",
    "pitch_vocab[:15]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing large dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "      <th>measure</th>\n",
       "      <th>node_id</th>\n",
       "      <th>pitch</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>A3</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>316</td>\n",
       "      <td>G3</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>317</td>\n",
       "      <td>A3</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>318</td>\n",
       "      <td>A3</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>bwv1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>319</td>\n",
       "      <td>A3</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     corpus  measure  node_id pitch duration\n",
       "315  bwv1.6        0      315    A3   1.0000\n",
       "316  bwv1.6        1      316    G3   1.0000\n",
       "317  bwv1.6        1      317    A3   1.0000\n",
       "318  bwv1.6        1      318    A3   1.0000\n",
       "319  bwv1.6        1      319    A3   1.0000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS = [\"corpus\",\"measure\", \"node_id\", \"pitch\", \"duration\"]\n",
    "tenors = all_files[all_files.partition == \"tenor\"][COLUMNS].\\\n",
    "    sort_values([\"corpus\",\"measure\",\"node_id\"])\n",
    "\n",
    "tenors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "ids_from_pitches = tf.keras.layers.StringLookup(\n",
    "    vocabulary=pitch_vocab, mask_token=None\n",
    ")\n",
    "\n",
    "pitches_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_pitches.get_vocabulary(), invert=True, mask_token=None,\n",
    ")\n",
    "\n",
    "ids_from_durations = tf.keras.layers.StringLookup(\n",
    "    vocabulary=duration_vocab, mask_token=None\n",
    ")\n",
    "\n",
    "durations_from_ids = tf.keras.layers.StringLookup(\n",
    "    vocabulary=ids_from_durations.get_vocabulary(), invert=True, mask_token=None\n",
    ")\n",
    "\n",
    "SEQ_LENGTH = 30\n",
    "\n",
    "combined_pitch_datasets = []\n",
    "combined_duration_datasets = []\n",
    "\n",
    "for corpus in tenors.corpus.unique():\n",
    "    sliced_data = tenors[tenors.corpus == corpus]\n",
    "    slice_pitch_ids = ids_from_pitches(sliced_data.pitch)\n",
    "    slice_duration_ids = ids_from_durations(sliced_data.duration)\n",
    "\n",
    "    pitch_ids_dataset = tf.data.Dataset.from_tensor_slices(slice_pitch_ids).\\\n",
    "        batch(SEQ_LENGTH+1, drop_remainder=True)\n",
    "\n",
    "    duration_ids_dataset = tf.data.Dataset.from_tensor_slices(slice_duration_ids).\\\n",
    "        batch(SEQ_LENGTH+1, drop_remainder=True)\n",
    "\n",
    "    combined_pitch_datasets.append(pitch_ids_dataset)\n",
    "    combined_duration_datasets.append(duration_ids_dataset)\n",
    "    \n",
    "global_pitch_dataset = reduce(lambda x, y: x.concatenate(y), combined_pitch_datasets)\n",
    "global_duration_dataset = reduce(lambda x, y: x.concatenate(y), combined_duration_datasets)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting intput and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['A1', 'A2'], ['A2', 'A3'])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Iterable, Tuple\n",
    "def split_input_target(sequence: Iterable) -> Tuple[Iterable]:  # type: ignore\n",
    "    \"\"\"function splits sequence\"\"\"\n",
    "    input_seq = sequence[:-1]  # type: ignore\n",
    "    target_seq = sequence[1:]  # type: ignore\n",
    "\n",
    "    return input_seq, target_seq\n",
    "\n",
    "split_input_target([\"A1\", \"A2\", \"A3\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [[  3 183   3 ... 183   3  51]\n",
      " [  3 183   3 ... 183   3  51]\n",
      " [  0  64  64 ...  94 183 153]\n",
      " ...\n",
      " [  3  33  70 ...  33   3 189]\n",
      " [ 64  94  64 ...  94  64  64]\n",
      " [ 64  51   3 ...  64  64  64]]\n",
      "Output: [[183   3   3 ...   3  51   3]\n",
      " [183   3   3 ...   3  51   3]\n",
      " [ 64  64  64 ... 183 153 183]\n",
      " ...\n",
      " [ 33  70  33 ...   3 189 189]\n",
      " [ 94  64  51 ...  64  64  94]\n",
      " [ 51   3  64 ...  64  64  64]]\n",
      "Input: [[  3  33  70 ...  94  70 160]\n",
      " [183   3  33 ...  33   3 124]\n",
      " [ 94  64  64 ... 123  64  33]\n",
      " ...\n",
      " [ 94  94   3 ...  94  70   3]\n",
      " [ 94   3  33 ...  70   3   3]\n",
      " [124 160 184 ...  33  94  94]]\n",
      "Output: [[ 33  70  33 ...  70 160 124]\n",
      " [  3  33  64 ...   3 124 124]\n",
      " [ 64  64  33 ...  64  33  33]\n",
      " ...\n",
      " [ 94   3  33 ...  70   3  94]\n",
      " [  3  33  64 ...   3   3 124]\n",
      " [160 184 124 ...  94  94   3]]\n",
      "Input: [[ 94  94   3 ...  94  70   3]\n",
      " [ 94   3  33 ...  70   3   3]\n",
      " [124 160 184 ...  33  94  94]\n",
      " ...\n",
      " [142  51 112 ... 142 154 154]\n",
      " [ 51  51 154 ...  51 112  64]\n",
      " [ 94   3   3 ...   3   3  33]]\n",
      "Output: [[ 94   3  33 ...  70   3  94]\n",
      " [  3  33  64 ...   3   3 124]\n",
      " [160 184 124 ...  94  94   3]\n",
      " ...\n",
      " [ 51 112  64 ... 154 154  51]\n",
      " [ 51 154  51 ... 112  64  94]\n",
      " [  3   3 183 ...   3  33  33]]\n",
      "Input: [[ 9  9  9 ...  5  5  9]\n",
      " [ 9  9  9 ...  5  5  9]\n",
      " [ 9 17 17 ...  9  3  3]\n",
      " ...\n",
      " [ 5  5  9 ...  5  5 17]\n",
      " [ 9  9  5 ...  9  9  9]\n",
      " [ 5  5 17 ...  9  9  9]]\n",
      "Output: [[ 9  9  9 ...  5  9  9]\n",
      " [ 9  9  9 ...  5  9  9]\n",
      " [17 17 17 ...  3  3  5]\n",
      " ...\n",
      " [ 5  9  9 ...  5 17  9]\n",
      " [ 9  5  5 ...  9  9  9]\n",
      " [ 5 17  9 ...  9  9  9]]\n",
      "Input: [[ 5  5  9 ...  9  9  9]\n",
      " [ 5  5  5 ...  5  9  9]\n",
      " [ 5  9  9 ...  3  5  5]\n",
      " ...\n",
      " [ 9  9  9 ...  9  9 25]\n",
      " [ 9  9  9 ...  9 25  9]\n",
      " [ 9  9  5 ... 25  9  9]]\n",
      "Output: [[ 5  9  9 ...  9  9  9]\n",
      " [ 5  5  5 ...  9  9  5]\n",
      " [ 9  9  9 ...  5  5  9]\n",
      " ...\n",
      " [ 9  9  9 ...  9 25  9]\n",
      " [ 9  9  9 ... 25  9  9]\n",
      " [ 9  5  5 ...  9  9  9]]\n",
      "Input: [[ 9  9  9 ...  9  9 25]\n",
      " [ 9  9  9 ...  9 25  9]\n",
      " [ 9  9  5 ... 25  9  9]\n",
      " ...\n",
      " [ 5  5  9 ...  9  9  9]\n",
      " [ 9  9  9 ...  9  9  5]\n",
      " [ 9  9  9 ...  9  9  9]]\n",
      "Output: [[ 9  9  9 ...  9 25  9]\n",
      " [ 9  9  9 ... 25  9  9]\n",
      " [ 9  5  5 ...  9  9  9]\n",
      " ...\n",
      " [ 5  9 17 ...  9  9  9]\n",
      " [ 9  9  5 ...  9  5  5]\n",
      " [ 9  9  9 ...  9  9  5]]\n"
     ]
    }
   ],
   "source": [
    "pitch_dataset = global_pitch_dataset.map(split_input_target).batch(64, drop_remainder=True)\n",
    "duration_dataset = global_duration_dataset.map(split_input_target).batch(64, drop_remainder=True)\n",
    "\n",
    "for input, target in pitch_dataset.take(3):\n",
    "    print(f\"Input: {input}\")\n",
    "    print(f\"Output: {target}\")\n",
    "\n",
    "for input, target in duration_dataset.take(3):\n",
    "    print(f\"Input: {input}\")\n",
    "    print(f\"Output: {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PitchModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, name=\"pitch_embedding\")\n",
    "        self.gru = tf.keras.layers.GRU(\n",
    "            rnn_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            name=\"pitch_gru\"\n",
    "        )\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size, name=\"pitch_dense\")\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = inputs\n",
    "        x = self.embedding(x, training=training)\n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        \n",
    "        x, states = self.gru(x, initial_state=states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "\n",
    "        if return_state:\n",
    "            return x, states\n",
    "\n",
    "        return x\n",
    "\n",
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(ids_from_pitches.get_vocabulary())\n",
    "# The embedding dimension\n",
    "EMBEDDING_DIM = 256\n",
    "# Number of RNN units\n",
    "RNN_UNITS = 256\n",
    "\n",
    "model = PitchModel(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=EMBEDDING_DIM,\n",
    "    rnn_units=RNN_UNITS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 30, 211)\n",
      "tf.Tensor(\n",
      "[[[-1.30140502e-02  1.32233733e-02 -1.77481174e-02 ...  1.47317424e-02\n",
      "   -2.82256352e-03 -1.14547685e-02]\n",
      "  [ 3.24489246e-03  9.63796861e-03  3.35728750e-04 ...  4.43810504e-03\n",
      "   -2.48514232e-03 -4.10472602e-03]\n",
      "  [-9.10016708e-03  1.60252675e-02 -1.65577326e-02 ...  1.69449002e-02\n",
      "   -6.66462351e-03 -1.16197364e-02]\n",
      "  ...\n",
      "  [ 8.53319280e-03  8.75596330e-03 -4.29142732e-03 ...  2.52400711e-03\n",
      "   -7.74160214e-03 -5.45661896e-05]\n",
      "  [-6.48778398e-03  1.44962426e-02 -1.85864735e-02 ...  1.61049925e-02\n",
      "   -8.71404447e-03 -1.01144528e-02]\n",
      "  [-2.01475453e-02  2.03341385e-03  3.82974185e-03 ...  7.60482159e-03\n",
      "   -2.44545024e-02 -2.03721970e-02]]\n",
      "\n",
      " [[-1.30140502e-02  1.32233733e-02 -1.77481174e-02 ...  1.47317424e-02\n",
      "   -2.82256352e-03 -1.14547685e-02]\n",
      "  [ 3.24489246e-03  9.63796861e-03  3.35728750e-04 ...  4.43810504e-03\n",
      "   -2.48514232e-03 -4.10472602e-03]\n",
      "  [-9.10016708e-03  1.60252675e-02 -1.65577326e-02 ...  1.69449002e-02\n",
      "   -6.66462351e-03 -1.16197364e-02]\n",
      "  ...\n",
      "  [ 8.53319280e-03  8.75596330e-03 -4.29142732e-03 ...  2.52400711e-03\n",
      "   -7.74160214e-03 -5.45661896e-05]\n",
      "  [-6.48778398e-03  1.44962426e-02 -1.85864735e-02 ...  1.61049925e-02\n",
      "   -8.71404447e-03 -1.01144528e-02]\n",
      "  [-2.01475453e-02  2.03341385e-03  3.82974185e-03 ...  7.60482159e-03\n",
      "   -2.44545024e-02 -2.03721970e-02]]\n",
      "\n",
      " [[ 1.86432526e-03 -4.04467713e-03 -5.26145706e-03 ...  1.45320105e-03\n",
      "   -6.53212797e-03  7.85278622e-03]\n",
      "  [-5.86342346e-03  5.84501214e-03  5.31146582e-03 ...  1.68955268e-03\n",
      "   -1.15462970e-02 -1.97316939e-03]\n",
      "  [-1.18575338e-02  1.10954857e-02  9.96111054e-03 ...  2.55707675e-03\n",
      "   -1.50914788e-02 -8.15637503e-03]\n",
      "  ...\n",
      "  [-2.63981819e-02  1.02887033e-02 -1.04721524e-02 ...  9.69486963e-03\n",
      "    3.44924675e-03 -2.02600807e-02]\n",
      "  [-5.74871153e-03  7.16420868e-03  4.22225613e-03 ...  9.85441729e-05\n",
      "   -1.26079912e-03 -1.06926803e-02]\n",
      "  [-2.88459915e-03  9.57419630e-03 -1.22688254e-02 ...  5.37133310e-05\n",
      "   -1.06976079e-02 -1.42183714e-03]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[-1.30140502e-02  1.32233733e-02 -1.77481174e-02 ...  1.47317424e-02\n",
      "   -2.82256352e-03 -1.14547685e-02]\n",
      "  [ 2.24337019e-02 -3.87827121e-03 -1.07998839e-02 ... -6.33155927e-03\n",
      "    4.75268718e-03 -1.01656793e-02]\n",
      "  [-1.52462665e-02  1.31603079e-02  9.36109573e-05 ... -5.57781849e-03\n",
      "   -6.81220880e-03 -1.29718762e-02]\n",
      "  ...\n",
      "  [ 2.14363374e-02 -8.74480698e-04 -2.82633537e-03 ... -2.19696816e-02\n",
      "    6.86663389e-03 -1.09411376e-02]\n",
      "  [-3.08188866e-03  1.35049932e-02 -2.22644154e-02 ...  1.41723827e-03\n",
      "    1.44687342e-03 -1.67535227e-02]\n",
      "  [ 1.08958303e-03  2.94130715e-03 -2.49464735e-02 ...  1.38731366e-02\n",
      "    2.94348947e-03 -3.57799907e-03]]\n",
      "\n",
      " [[-7.44487997e-03  7.99178891e-03  8.12350772e-03 ...  2.20417441e-03\n",
      "   -9.01785772e-03 -4.47604107e-03]\n",
      "  [-2.19255388e-02  6.30778959e-03  7.30254687e-04 ...  2.88120378e-03\n",
      "    6.60282886e-03 -1.31015107e-02]\n",
      "  [-2.06361283e-02  9.43085458e-03  8.27829726e-03 ...  3.22225783e-03\n",
      "   -8.42096657e-03 -1.31160095e-02]\n",
      "  ...\n",
      "  [-2.99045052e-02  1.12114251e-02  3.13460501e-03 ...  4.30658646e-03\n",
      "   -1.77768292e-03 -2.08736826e-02]\n",
      "  [-2.58934349e-02  1.22237997e-02  9.47443675e-03 ...  4.59258631e-03\n",
      "   -1.40748788e-02 -1.82805769e-02]\n",
      "  [-2.41985731e-02  1.34077230e-02  1.21153891e-02 ...  4.92835697e-03\n",
      "   -1.91572532e-02 -1.76501032e-02]]\n",
      "\n",
      " [[-7.44487997e-03  7.99178891e-03  8.12350772e-03 ...  2.20417441e-03\n",
      "   -9.01785772e-03 -4.47604107e-03]\n",
      "  [-2.56511383e-02  1.64292194e-03  1.69654284e-02 ... -2.91961245e-04\n",
      "   -2.30396688e-02 -2.06787251e-02]\n",
      "  [-2.49018408e-02  1.61390547e-02 -8.99589434e-03 ...  1.22319106e-02\n",
      "   -1.38549749e-02 -2.18744799e-02]\n",
      "  ...\n",
      "  [-2.10022144e-02  1.20355459e-02  1.16603058e-02 ...  7.77010340e-04\n",
      "   -2.17351317e-02 -1.78043228e-02]\n",
      "  [-1.81731377e-02  1.50138428e-02  1.26654822e-02 ...  1.14666345e-03\n",
      "   -2.02451013e-02 -1.50048193e-02]\n",
      "  [-1.83866788e-02  1.62560195e-02  1.30312480e-02 ...  2.45249737e-03\n",
      "   -2.05715820e-02 -1.49098150e-02]]], shape=(64, 30, 211), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in pitch_dataset.take(1):\n",
    "    example_predictions = model(input_example)\n",
    "    print(example_predictions.shape)\n",
    "    print(example_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"pitch_model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " pitch_embedding (Embedding)  multiple                 54016     \n",
      "                                                                 \n",
      " pitch_gru (GRU)             multiple                  394752    \n",
      "                                                                 \n",
      " pitch_dense (Dense)         multiple                  54227     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 502,995\n",
      "Trainable params: 502,995\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([167,  34, 150,  79, 137,   6, 177,  72, 145, 145,  91, 142, 149,\n",
       "        17, 117,   3,  99, 172,   3,  60,  98, 153,  96, 210,  91, 163,\n",
       "        90, 172,  68,  49], dtype=int64)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(\n",
    "    example_predictions[0], num_samples=1)\n",
    "\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " [b'A3' b'G3' b'A3' b'A3' b'A3' b'F3' b'F4' b'F4' b'F4' b'F4' b'G4' b'F4'\n",
      " b'D4' b'E4' b'F4' b'E4' b'D4' b'E4' b'C4' b'A3' b'F3' b'G3' b'A3' b'A3'\n",
      " b'G3' b'A3' b'F3' b'G3' b'A3' b'B-3']\n",
      "\n",
      "Next Char Predictions:\n",
      " [b'F##5' b'B4' b'E--6' b'C-1' b'E##5' b'A6' b'F--3' b'C#6' b'E--1' b'E--1'\n",
      " b'D1' b'E-4' b'E--5' b'A##5' b'D--3' b'A3' b'D#3' b'F-4' b'A3' b'B--6'\n",
      " b'D#2' b'F3' b'D6' b'G--6' b'D1' b'F##1' b'C--6' b'F-4' b'C#2' b'B-1']\n"
     ]
    }
   ],
   "source": [
    "print(\"Input:\\n\", pitches_from_ids(input_example[0]).numpy())\n",
    "print()\n",
    "print(\"Next Char Predictions:\\n\", pitches_from_ids(sampled_indices).numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape: (64, 30, 211)\n",
      "Mean loss: 210.66091918945312\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "example_mean_loss = loss(target_example, example_predictions)\n",
    "print(f\"Prediction shape: {example_predictions.shape}\")\n",
    "print(f\"Mean loss: {tf.exp(example_mean_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "checkpoint_dir = r\".\\training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"chkpt_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_dir, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "9/9 [==============================] - 2s 33ms/step - loss: 5.1600\n",
      "Epoch 2/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 3.4243\n",
      "Epoch 3/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.8280\n",
      "Epoch 4/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.6750\n",
      "Epoch 5/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.6001\n",
      "Epoch 6/40\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 2.5272\n",
      "Epoch 7/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.4546\n",
      "Epoch 8/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 2.3773\n",
      "Epoch 9/40\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.2956\n",
      "Epoch 10/40\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.2134\n",
      "Epoch 11/40\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.1365\n",
      "Epoch 12/40\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.0795\n",
      "Epoch 13/40\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 2.0428\n",
      "Epoch 14/40\n",
      "9/9 [==============================] - 0s 20ms/step - loss: 2.0146\n",
      "Epoch 15/40\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.9901\n",
      "Epoch 16/40\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.9675\n",
      "Epoch 17/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.9468\n",
      "Epoch 18/40\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.9308\n",
      "Epoch 19/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.9189\n",
      "Epoch 20/40\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.9094\n",
      "Epoch 21/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.9010\n",
      "Epoch 22/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.8930\n",
      "Epoch 23/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.8850\n",
      "Epoch 24/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.8766\n",
      "Epoch 25/40\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.8681\n",
      "Epoch 26/40\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.8601\n",
      "Epoch 27/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.8529\n",
      "Epoch 28/40\n",
      "9/9 [==============================] - 0s 19ms/step - loss: 1.8466\n",
      "Epoch 29/40\n",
      "9/9 [==============================] - 0s 15ms/step - loss: 1.8411\n",
      "Epoch 30/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.8359\n",
      "Epoch 31/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.8309\n",
      "Epoch 32/40\n",
      "9/9 [==============================] - 0s 16ms/step - loss: 1.8258\n",
      "Epoch 33/40\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.8206\n",
      "Epoch 34/40\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.8153\n",
      "Epoch 35/40\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.8102\n",
      "Epoch 36/40\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1.8053\n",
      "Epoch 37/40\n",
      "9/9 [==============================] - 0s 17ms/step - loss: 1.8007\n",
      "Epoch 38/40\n",
      "9/9 [==============================] - 0s 18ms/step - loss: 1.7962\n",
      "Epoch 39/40\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 1.7919\n",
      "Epoch 40/40\n",
      "9/9 [==============================] - 0s 21ms/step - loss: 1.7877\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 40\n",
    "history = model.fit(pitch_dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keras.layers.preprocessing.string_lookup.StringLookup"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pitches_from_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids=<tf.Tensor 'RaggedToTensor/RaggedTensorToTensor:0' shape=(1, None) dtype=int64>\n",
      "predicted_logits=<tf.Tensor 'pitch_model_4/pitch_dense/BiasAdd:0' shape=(1, None, 211) dtype=float32>\n",
      "input_ids=<tf.Tensor 'RaggedToTensor/RaggedTensorToTensor:0' shape=(1, None) dtype=int64>\n",
      "predicted_logits=<tf.Tensor 'pitch_model_4/pitch_dense/BiasAdd:0' shape=(1, None, 211) dtype=float32>\n",
      "result=['A1', 'G1', 'A1', 'F#4', 'E4', 'D4', 'E4', 'F4', 'G4', 'C#4', 'D4', 'C#4', 'D4', 'G4', 'F#4', 'E4', 'B3', 'E4', 'D4', 'D4', 'C#4', 'A3', 'A3', 'G3', 'F#3', 'G3', 'B3', 'B3', 'C4', 'D4']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self, \n",
    "        model: tf.keras.Model, \n",
    "        pitches_from_ids: tf.keras.layers.StringLookup,\n",
    "        ids_from_pitches: tf.keras.layers.StringLookup,\n",
    "        temperature: float=1.,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.pitches_from_ids = pitches_from_ids\n",
    "        self.ids_from_pitches = ids_from_pitches\n",
    "        \n",
    "        skip_ids = self.ids_from_pitches(['[UNK]'])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "            values = [-float(\"inf\")]*len(skip_ids),\n",
    "            indices=skip_ids,\n",
    "            dense_shape=[len(ids_from_pitches.get_vocabulary())]\n",
    "        )\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        # convert tokens into token ids\n",
    "        raged_input = tf.ragged.stack([tf.convert_to_tensor(inputs)])\n",
    "        input_ids = self.ids_from_pitches(raged_input).to_tensor()\n",
    "        print(f\"{input_ids=}\")\n",
    "\n",
    "        # run the model\n",
    "        # predicted logits shape is [batch, char, next_char_logits]\n",
    "        predicted_logits, states = self.model(inputs=input_ids, states=states, return_state=True)\n",
    "        print(f\"{predicted_logits=}\")\n",
    "\n",
    "        # use only the last prediction\n",
    "        predicted_logits = predicted_logits[:,-1, :]\n",
    "        predicted_logits = predicted_logits/self.temperature\n",
    "\n",
    "        #apply prediction_mask : prevent [\"UNK\"] from being generated\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "\n",
    "        #sample the output logits to generate token ids\n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "\n",
    "        # convert from token ids to characters\n",
    "        predicted_pitches = self.pitches_from_ids(predicted_ids)\n",
    "\n",
    "        return predicted_pitches, states\n",
    "\n",
    "\n",
    "one_step_model = OneStep(model, pitches_from_ids, ids_from_pitches)\n",
    "start = time.time()\n",
    "states = None\n",
    "next_pitch = [\"A1\", \"G1\", \"A1\", ]\n",
    "result = next_pitch\n",
    "\n",
    "for n in range(27):\n",
    "    next_pitch, states = one_step_model.generate_one_step(\n",
    "        next_pitch, states=states)\n",
    "    result.append(next_pitch.numpy()[0].decode())\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"{result=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315    1.0000\n",
       "316    1.0000\n",
       "317    1.0000\n",
       "318    1.0000\n",
       "319    1.0000\n",
       "320    1.0000\n",
       "321    1.0000\n",
       "322    1.0000\n",
       "323    1.0000\n",
       "324    1.0000\n",
       "325    1.0000\n",
       "326    0.5000\n",
       "327    0.5000\n",
       "328    1.0000\n",
       "329    0.5000\n",
       "330    0.5000\n",
       "331    1.0000\n",
       "332    1.0000\n",
       "333    0.5000\n",
       "334    0.5000\n",
       "335    0.5000\n",
       "336    0.5000\n",
       "337    1.0000\n",
       "338    0.5000\n",
       "339    0.5000\n",
       "340    0.5000\n",
       "341    0.5000\n",
       "342    0.5000\n",
       "343    0.5000\n",
       "344    1.0000\n",
       "Name: duration, dtype: object"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "durations = tenors[tenors.corpus == \"bwv1.6\"].duration[:30]\n",
    "durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv1526'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                \n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv1526');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAARwA/wMAAOAAQIgAkCFaiACAIQAAkB9aiACAHwAAkCFaiACAIQAAkEJaiACAQgAAkEBaiACAQAAAkD5aiACAPgAAkEBaiACAQAAAkEFaiACAQQAAkENaiACAQwAAkD1aiACAPQAAkD5aiACAPgAAkD1ahACAPQAAkD5ahACAPgAAkENaiACAQwAAkEJahACAQgAAkEBahACAQAAAkDtaiACAOwAAkEBaiACAQAAAkD5ahACAPgAAkD5ahACAPgAAkD1ahACAPQAAkDlahACAOQAAkDlaiACAOQAAkDdahACANwAAkDZahACANgAAkDdahACANwAAkDtahACAOwAAkDtahACAOwAAkDxahACAPAAAkD5aiACAPgCIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import music21 as mu\n",
    "\n",
    "\n",
    "generated_stream = mu.stream.Stream()\n",
    "for el, dur in zip(result, durations):\n",
    "    generated_stream.append(mu.note.Note(el, quarterLength=float(dur)))\n",
    "generated_stream.show(\"midi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <div id='midiPlayerDiv1049'></div>\n",
       "                <link rel=\"stylesheet\" href=\"//cuthbertLab.github.io/music21j/css/m21.css\"\n",
       "                    type=\"text/css\" />\n",
       "                \n",
       "                <script>\n",
       "                require.config({\n",
       "                    paths: {'music21': '//cuthbertLab.github.io/music21j/src/music21'}\n",
       "                });\n",
       "                require(['music21'], function() {\n",
       "                               mp = new music21.miditools.MidiPlayer();\n",
       "                               mp.addPlayer('#midiPlayerDiv1049');\n",
       "                               mp.base64Load('data:audio/midi;base64,TVRoZAAAAAYAAQACBABNVHJrAAAAFAD/UQMHoSAA/1gEBAIYCIgA/y8ATVRyawAAARwA/wMAAOAAQIgAkDlaiACAOQAAkDdaiACANwAAkDlaiACAOQAAkDlaiACAOQAAkDlaiACAOQAAkDVaiACANQAAkEFaiACAQQAAkEFaiACAQQAAkEFaiACAQQAAkEFaiACAQQAAkENaiACAQwAAkEFahACAQQAAkD5ahACAPgAAkEBaiACAQAAAkEFahACAQQAAkEBahACAQAAAkD5aiACAPgAAkEBaiACAQAAAkDxahACAPAAAkDlahACAOQAAkDVahACANQAAkDdahACANwAAkDlaiACAOQAAkDlahACAOQAAkDdahACANwAAkDlahACAOQAAkDVahACANQAAkDdahACANwAAkDlahACAOQAAkDpaiACAOgCIAP8vAA==');\n",
       "                        });\n",
       "                </script>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_stream = mu.stream.Stream()\n",
    "original_notes = tenors[tenors.corpus == \"bwv1.6\"].pitch[:30]\n",
    "for el, dur in zip(original_notes, durations):\n",
    "    original_stream.append(mu.note.Note(el, quarterLength=float(dur)))\n",
    "original_stream.show(\"midi\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('music_project')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b5d02f2b44b067a083e90d534afbf8436d8323fa370051d74cde8b14cc02c2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
